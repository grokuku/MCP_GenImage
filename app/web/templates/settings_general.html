{% extends "base.html" %}

{% block title %}{{ title }} - MCP GenImage{% endblock %}

{% block content %}
<div class="container">
    <h1>{{ title }}</h1>
    <p>Configure general application settings.</p>

    <div class="form-section">
        <form action="/settings/general" method="post">

            <h2 style="border-bottom: 1px solid #444; padding-bottom: 0.3em; margin-bottom: 1em;">Image Output & URLs
            </h2>

            <div class="form-group">
                <label for="output_url_base">Output URL Base</label>
                <input type="text" id="output_url_base" name="output_url_base" value="{{ settings.output_url_base }}"
                    placeholder="e.g., http://localhost:8001/outputs">
                <small>The public base URL where generated images can be accessed. This is returned by the API.</small>
            </div>

            <h2 style="border-bottom: 1px solid #444; padding-bottom: 0.3em; margin-top: 2em; margin-bottom: 1em;">
                Upscale Tool Settings</h2>

            <div class="form-group">
                <label for="default_upscale_denoise">Default Upscale Denoise</label>
                <input type="number" id="default_upscale_denoise" name="default_upscale_denoise"
                    value="{{ settings.default_upscale_denoise }}" placeholder="e.g., 0.2" step="0.01" min="0" max="1">
                <small>The default denoise value to use for the 'upscale_image' tool if not specified in the API
                    call.</small>
            </div>

            <h2 style="border-bottom: 1px solid #444; padding-bottom: 0.3em; margin-top: 2em; margin-bottom: 1em;">
                Prompt Enhancement Settings</h2>

            <div class="form-group">
                <label for="prompt_enhancement_ollama_instance_id">Ollama Instance for Prompt Enhancement</label>
                <select id="prompt_enhancement_ollama_instance_id" name="prompt_enhancement_ollama_instance_id">
                    <option value="">-- Disabled --</option>
                    {% for instance in ollama_instances %}
                    <option value="{{ instance.id }}" data-url="{{ instance.base_url }}" {% if
                        settings.prompt_enhancement_ollama_instance_id | string==instance.id | string %}selected{% endif
                        %}>
                        {{ instance.name }} ({{ instance.base_url }})
                    </option>
                    {% endfor %}
                </select>
                <small>Select an active Ollama instance to enable the 'enhance_prompt' feature.</small>
            </div>

            <div class="form-group">
                <label for="prompt_enhancement_model_name">Enhancement Model Name</label>
                <select id="prompt_enhancement_model_name" name="prompt_enhancement_model_name">
                    <option value="">-- Select an instance first --</option>
                </select>
                <small>The name of the text generation model to use for enhancement.</small>
            </div>

            <button type="submit" class="btn btn-primary">Save Settings</button>
        </form>
    </div>
</div>
{% endblock %}

{% block scripts %}
<script>
    document.addEventListener('DOMContentLoaded', () => {
        const instanceSelect = document.getElementById('prompt_enhancement_ollama_instance_id');
        const modelSelect = document.getElementById('prompt_enhancement_model_name');
        const currentlySavedModel = "{{ settings.prompt_enhancement_model_name or '' }}";

        async function updateModelList() {
            const selectedOption = instanceSelect.options[instanceSelect.selectedIndex];
            const instanceUrl = selectedOption.dataset.url;

            // Clear current model list
            modelSelect.innerHTML = '<option value="">Loading...</option>';

            if (!instanceUrl) {
                modelSelect.innerHTML = '<option value="">-- Select an instance first --</option>';
                return;
            }

            try {
                const response = await fetch('/api/v1/ollama/list-models', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ ollama_api_url: instanceUrl })
                });

                if (!response.ok) {
                    const errData = await response.json();
                    throw new Error(errData.detail || 'Failed to fetch models');
                }

                const data = await response.json();
                modelSelect.innerHTML = '<option value="">-- Select a model --</option>'; // Reset

                if (data.models && data.models.length > 0) {
                    data.models.forEach(model => {
                        const option = document.createElement('option');
                        option.value = model.name;
                        option.textContent = model.name;
                        if (model.name === currentlySavedModel) {
                            option.selected = true;
                        }
                        modelSelect.appendChild(option);
                    });
                } else {
                    modelSelect.innerHTML = '<option value="">-- No models found on this instance --</option>';
                }

            } catch (error) {
                console.error('Error fetching Ollama models:', error);
                modelSelect.innerHTML = `<option value="">-- Error: ${error.message} --</option>`;
            }
        }

        // Add event listener and trigger once on page load
        instanceSelect.addEventListener('change', updateModelList);
        updateModelList();
    });
</script>
{% endblock %}