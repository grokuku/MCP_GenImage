{% extends "base.html" %}

{% block title %}{{ title }} - MCP GenImage{% endblock %}

{% block content %}
<div class="container">
    <h1>{{ title }}</h1>
    <p>Configure general application settings and the connection to an Ollama server for prompt enhancement.</p>

    <div class="form-section">
        <form action="/settings/ollama" method="post">

            <h2 style="border-bottom: 1px solid #444; padding-bottom: 0.3em; margin-bottom: 1em;">General Settings</h2>

            <div class="form-group">
                <label for="output_url_base">Output URL Base</label>
                <input type="text" id="output_url_base" name="output_url_base" value="{{ settings.output_url_base }}"
                    placeholder="e.g., http://localhost:8001/outputs">
                <small>The public base URL where generated images can be accessed. This is returned by the API.</small>
            </div>

            <h2 style="border-bottom: 1px solid #444; padding-bottom: 0.3em; margin-top: 2em; margin-bottom: 1em;">
                Upscale Settings</h2>

            <div class="form-group">
                <label for="default_upscale_denoise">Default Upscale Denoise</label>
                <input type="number" id="default_upscale_denoise" name="default_upscale_denoise"
                    value="{{ settings.default_upscale_denoise }}" placeholder="e.g., 0.2" step="0.01" min="0" max="1">
                <small>The default denoise value to use for the 'upscale_image' tool if not specified in the API
                    call.</small>
            </div>

            <h2 style="border-bottom: 1px solid #444; padding-bottom: 0.3em; margin-top: 2em; margin-bottom: 1em;">
                Ollama Settings</h2>

            <p>Leave the URL blank to disable the prompt enhancement feature.</p>

            <div class="form-group">
                <label for="ollama_api_url">Ollama Server Base URL</label>
                <input type="text" id="ollama_api_url" name="ollama_api_url" value="{{ settings.ollama_api_url }}"
                    placeholder="e.g., http://host.docker.internal:11434">
                <small>Enter the URL and wait a moment for the model list to refresh.</small>
            </div>

            <div class="form-group">
                <label for="ollama_model_name">LLM Model Name</label>
                <select id="ollama_model_name" name="ollama_model_name">
                    <!-- Options will be populated by JavaScript -->
                </select>
                <div id="models-loader" style="display: none; margin-top: 5px;">Loading models...</div>
                <div id="models-error" style="display: none; margin-top: 5px; color: #ff8a8a;"></div>
            </div>

            <div class="form-group">
                <label for="ollama_context_window">Context Window</label>
                <input type="number" id="ollama_context_window" name="ollama_context_window"
                    value="{{ settings.ollama_context_window }}" placeholder="e.g., 2048">
                <small>Max number of tokens for the context. Set to 0 for default.</small>
            </div>

            <div class="form-group">
                <label for="ollama_keep_alive">Keep Alive</label>
                <input type="text" id="ollama_keep_alive" name="ollama_keep_alive"
                    value="{{ settings.ollama_keep_alive }}" placeholder="e.g., 5m">
                <small>Time the model stays loaded in memory (e.g., "5m", "1h", "-1" for permanent).</small>
            </div>

            <button type="submit" class="btn btn-primary">Save Settings</button>
        </form>
    </div>
</div>
{% endblock %}

{% block scripts %}
<script>
    document.addEventListener('DOMContentLoaded', () => {
        const apiUrlInput = document.getElementById('ollama_api_url');
        const modelSelect = document.getElementById('ollama_model_name');
        const loader = document.getElementById('models-loader');
        const errorDisplay = document.getElementById('models-error');
        const currentlySavedModel = "{{ settings.ollama_model_name }}";
        let debounceTimer;

        async function fetchAndPopulateModels() {
            const apiUrl = apiUrlInput.value.trim();
            modelSelect.innerHTML = '';
            loader.style.display = 'block';
            errorDisplay.style.display = 'none';

            if (!apiUrl) {
                loader.style.display = 'none';
                return;
            }

            try {
                const response = await fetch('/api/v1/ollama/list-models', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ ollama_api_url: apiUrl })
                });
                if (!response.ok) {
                    const err = await response.json();
                    throw new Error(err.detail || 'Failed to fetch models.');
                }
                const data = await response.json();

                if (data.models && data.models.length > 0) {
                    data.models.forEach(model => {
                        const option = document.createElement('option');
                        option.value = model.name;
                        option.textContent = model.name;
                        if (model.name === currentlySavedModel) option.selected = true;
                        modelSelect.appendChild(option);
                    });
                } else {
                    const option = document.createElement('option');
                    option.textContent = "No models found on server.";
                    option.disabled = true;
                    modelSelect.appendChild(option);
                }
            } catch (error) {
                errorDisplay.textContent = 'Error: ' + error.message;
                errorDisplay.style.display = 'block';
            } finally {
                loader.style.display = 'none';
            }
        }

        apiUrlInput.addEventListener('input', () => {
            clearTimeout(debounceTimer);
            debounceTimer = setTimeout(fetchAndPopulateModels, 500);
        });

        fetchAndPopulateModels();
    });
</script>
{% endblock %}